[BASE]
do_train = True
do_save_model = True
do_hyperparameter_search = False
do_test = False
do_toy = False
do_majority_baseline = False
do_average_runs = False
do_consistency_check_mode = False
do_merge_questions = True
do_add_punc = True

splits_directory = NONE
annotations_directory = NONE
input_dataframe = dataset.pkl
gpu_node = 0

pretrained_bert_model = deepset/gbert-large
fine_tuned_model_path = NONE
runs_paths = NONE

output_dir = BERT-large-context-run-0/
log_filename = BERT-large-context-run-0-train.log

[PARAM]
seed = 15
context_mode = True
optimizer = adamw_torch
epochs = 4
batch_size = 16
learning_rate = 2.9206589963284678e-05
weight_decay = 0.01
warmup_ratio = 0.1